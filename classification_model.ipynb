{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-16 13:48:52.204686: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-16 13:48:53.259495: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/karan/Secondary/dev/ml/.venv/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-01-16 13:48:53.259521: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-16 13:48:53.328443: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-01-16 13:48:54.795283: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/karan/Secondary/dev/ml/.venv/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-01-16 13:48:54.795431: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/karan/Secondary/dev/ml/.venv/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-01-16 13:48:54.795444: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>normal</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/final_data/1.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/final_data/10.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/final_data/100.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/final_data/101.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/final_data/102.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>data/final_data/103.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>data/final_data/104.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>data/final_data/105.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>data/final_data/106.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>data/final_data/107.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 file_name  normal  negative  positive\n",
       "0    data/final_data/1.jpg       0         2         0\n",
       "1   data/final_data/10.jpg       0         1         0\n",
       "2  data/final_data/100.jpg       1         0         0\n",
       "3  data/final_data/101.jpg       1         0         0\n",
       "4  data/final_data/102.jpg       1         0         0\n",
       "5  data/final_data/103.jpg       0         3         0\n",
       "6  data/final_data/104.jpg       1         0         0\n",
       "7  data/final_data/105.jpg       1         0         0\n",
       "8  data/final_data/106.jpg       1         0         0\n",
       "9  data/final_data/107.jpg       1         0         0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CSV_FILE = r\"data/csv/road_classification.csv\"\n",
    "\n",
    "features = pd.read_csv(CSV_FILE)\n",
    "\n",
    "features.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "file_name    0\n",
       "normal       0\n",
       "negative     0\n",
       "positive     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "img_names = features['file_name']\n",
    "labels = features.drop('file_name', axis=1)\n",
    "\n",
    "img_names_shuffled, labels_shuffled = shuffle(img_names, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_img, X_test_img, y_train, y_test = train_test_split(\n",
    "    img_names_shuffled, labels_shuffled,\n",
    "    test_size=0.2,\n",
    "    random_state=101\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_class = y_train[['normal', 'negative', 'positive']]\n",
    "test_class = y_test[['normal', 'negative', 'positive']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(260, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_by_loc(location: str) -> cv2.Mat:\n",
    "    img = cv2.imread(location)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = img/255\n",
    "    img = cv2.resize(img, (800,800))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageGenerator(keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, img_files, img_class_num, batch_size = 32) -> None:\n",
    "        self.img_files = img_files\n",
    "        self.img_class_num = img_class_num\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return (np.ceil(len(self.img_files) / float(self.batch_size))).astype(np.int)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.img_files[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
    "        batch_y = [np.array(self.img_class_num[idx * self.batch_size : (idx + 1) * self.batch_size])]\n",
    "\n",
    "        return np.array([\n",
    "            get_img_by_loc(f'{file_name}')\n",
    "            for file_name in batch_x\n",
    "        ]), batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "train_batch_gen = ImageGenerator(X_train_img, train_class, batch_size)\n",
    "test_batch_gen = ImageGenerator(X_test_img, test_class, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, Input, Activation, Add, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-16 14:34:55.097368: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-16 14:34:55.098100: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/karan/Secondary/dev/ml/.venv/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-01-16 14:34:55.098332: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/karan/Secondary/dev/ml/.venv/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-01-16 14:34:55.098512: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/karan/Secondary/dev/ml/.venv/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-01-16 14:34:55.098681: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/karan/Secondary/dev/ml/.venv/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-01-16 14:34:55.098852: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/karan/Secondary/dev/ml/.venv/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-01-16 14:34:55.099017: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/karan/Secondary/dev/ml/.venv/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-01-16 14:34:55.099212: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/karan/Secondary/dev/ml/.venv/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-01-16 14:34:55.099378: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/karan/Secondary/dev/ml/.venv/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-01-16 14:34:55.099404: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-01-16 14:34:55.102194: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-16 14:34:55.814746: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 4657283072 exceeds 10% of free system memory.\n",
      "2023-01-16 14:34:59.291832: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 4657283072 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "input_ = Input(shape=(800,800,1), name=\"Input Layer\")\n",
    "\n",
    "conv_1 = Conv2D(32, kernel_size= (4, 4), name=\"conv_1\")(input_)\n",
    "act_1  = Activation(\"relu\", name=\"act_1\")(conv_1)\n",
    "pool_1 = MaxPooling2D(pool_size=(8, 8), strides=(1,1), padding=\"valid\", name=\"pool_1\")(act_1)\n",
    "\n",
    "conv_2 = Conv2D(64, kernel_size = (8, 8), name = \"conv_2\")(pool_1)\n",
    "act_2 = Activation(\"relu\", name = \"act_2\")(conv_2)\n",
    "pool_2 = MaxPooling2D(pool_size = (4, 4), strides = (1, 1), padding = \"valid\", name = \"pool_2\")(act_2)\n",
    "\n",
    "conv_3 = Conv2D(32, kernel_size = (4, 4), name = \"conv_3\")(pool_2)\n",
    "act_3 = Activation(\"relu\", name = \"act_3\")(conv_3)\n",
    "pool_3 = MaxPooling2D(pool_size = (8, 8), strides = (1, 1), padding = \"valid\", name = \"pool_3\")(act_3)\n",
    "\n",
    "conv_4 = Conv2D(16, kernel_size = (4, 4), name = \"conv_4\")(pool_3)\n",
    "act_4 = Activation(\"relu\", name = \"act_4\")(conv_4)\n",
    "pool_4 = MaxPooling2D(pool_size = (4, 4), strides = (1, 1), padding = \"valid\", name = \"pool_4\")(act_4)\n",
    "\n",
    "conv_5 = Conv2D(16, kernel_size = (8, 8), name = \"conv_5\")(pool_4)\n",
    "act_5 = Activation(\"relu\", name = \"act_5\")(conv_5)\n",
    "pool_5 = MaxPooling2D(pool_size = (4, 4), strides = (1, 1), padding = \"valid\", name = \"pool_5\")(act_5)\n",
    "\n",
    "flat_1 = Flatten(name = \"flat_1\")(pool_5)\n",
    "\n",
    "dense_1 = Dense(128, activation = \"relu\", name = \"dense_1\")(flat_1)\n",
    "batch_1 = BatchNormalization(name=\"batch_1\")(dense_1)\n",
    "dense_2 = Dense(64, activation=\"relu\", name=\"dense_2\")(batch_1)\n",
    "batch_2 = BatchNormalization(name=\"batch_2\")(dense_2)\n",
    "dense_3 = Dense(32, activation=\"relu\", name=\"dense_3\")(batch_2)\n",
    "drop_1 = Dropout(rate=0.4, name=\"drop_1\")(dense_3)\n",
    "dense_4 = Dense(16, activation=\"relu\", name=\"dense_4\")(drop_1)\n",
    "drop_2 = Dropout(rate=0.4, name=\"drop_2\")(dense_4)\n",
    "dense_5 = Dense(8, activation=\"relu\", name=\"dense_5\")(drop_2)\n",
    "img_class = Dense(3, activation=\"softmax\", name=\"img_class\")(dense_5)\n",
    "\n",
    "model = Model(inputs = input_, outputs = img_class)\n",
    "opt = tensorflow.keras.optimizers.SGD(learning_rate=0.01)\n",
    "\n",
    "model.compile(\n",
    "    loss = {\n",
    "        \"img_class\" : \"categorical_crossentropy\"\n",
    "    },\n",
    "    optimizer=opt,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0 (default, Dec 23 2022, 19:10:41) [GCC 12.2.1 20221121 (Red Hat 12.2.1-4)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d60e70248abc41e12b3974e4e67bf504e915c7d57ff25fea1fbcc1f591da07f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
